{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L3b: Praktyczny Machine Learning w Pythonie\n",
    "<br>\n",
    "<img src=\"figures/L1/dilbert-2213.gif\">\n",
    "\n",
    "## Rozpoznawanie cyfr\n",
    "\n",
    "Nasz model będzie składał się z 2 kroków:\n",
    "1. Zmniejszenie ilości wymiarów\n",
    "2. Klasyfikacja modelem liniowym\n",
    "\n",
    "Najpierw jednak musimy zapoznać się ze zbiorem danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST\n",
    "\n",
    "<img src=\"figures/L1/mnist_originals.png\">\n",
    "\n",
    "MNIST to baza danych odręcznie napisanych cyfr około 20 lat temu. Ludzie są w stanie rozpoznać ok. 99,5% cyfr z tego zbioru poprawnie.\n",
    "Zobaczymy ile nam się uda!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = mnist.data[0]\n",
    "print \"Pierwsz obrazek z \", mnist.data.shape[0], \":\", img # Pixele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Możemy sobie narysować wcześniej wypisaną cyfrę\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(img.reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import linear_model, decomposition\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Krok 1: wczytanie i podzielenie danych\n",
    "\n",
    "Skalowanie jest bardzo ważne. Dzięki temu mamy średnią danej cechy 0 i wariancję 1 (mówiąc po ludzku, dane będą bardziej  przypominały kulke w przestrzeni wejściowej)\n",
    "\n",
    "<img src=\"figures/L1/prepro2.jpeg\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Wczytujemy dane i skalujemy\n",
    "X, Y = mnist.data.astype(\"float64\"), mnist.target \n",
    "X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tak jak wspomniałem algorytm trenujemy na innych danych niż testujemy. **To bardzo ważne**. Do każdych danych da się dopasować taki model, który idealnie na nich odpowiada (np. poprzez zapamiętanie wszystkich przykładów). Jeśli tak zrobimy, to mówimy że nasz model **zoverfitował**.\n",
    "\n",
    "<img src=\"figures/L1/underfitting-overfitting.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dzielimy na dane trenujące i testujące\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Krok 2: dopasujmy pare modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Na wszystkich przykladach osiaga 92% dokladnosci. \n",
    "N = 500 # Podzbiór danych\n",
    "model = LogisticRegression(C=0.001) # Model z domyślnymi parametrami\n",
    "model.fit(X_train[0:N], Y_train[0:N])\n",
    "\n",
    "Y_test_predicted = model.predict(X_test)\n",
    "print \"Dokładność modelu wytrenowanego na \",N, \" przykladach to: \",100*sklearn.metrics.accuracy_score(Y_test, Y_test_predicted), \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Na wszystkich przykladach osiaga 92% dokladnosci. \n",
    "N = 500 # Podzbiór danych\n",
    "model = LogisticRegression(C=1) # Mniej regularyzacji, a taka sama dokladnosc\n",
    "model.fit(X_train[0:N], Y_train[0:N])\n",
    "\n",
    "Y_test_predicted = model.predict(X_test)\n",
    "print \"Dokładność modelu wytrenowanego na \",N, \" przykladach to: \",100*sklearn.metrics.accuracy_score(Y_test, Y_test_predicted), \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Przyklad zaklasyfikowany jako \", model.predict(X_test[5])\n",
    "plt.imshow(X_test[5].reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cwiczenie 1 (1 pkt)\n",
    "\n",
    "Prosze narysowac wykres (plt.plot) dokladnosci w zaleznosci od wartosci C na zbiorze treningowym i testowym (dla tych N=500 przykladow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 500\n",
    "space = np.linspace(0.001,1,10)\n",
    "res = []\n",
    "for c in space:\n",
    "    model = LogisticRegression(C=c) \n",
    "    model.fit(X_train[0:N], Y_train[0:N])\n",
    "    Y_test_predicted = model.predict(X_test)\n",
    "    res.append(100*sklearn.metrics.accuracy_score(Y_test, Y_test_predicted))\n",
    "\n",
    "plt.plot(space,res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cwiczenie 2 (2 pkt)\n",
    "\n",
    "(Punkt za narysowanie oraz punkt za poprawne wytłumaczenie)\n",
    "\n",
    "Proszę narysować jak wyglądaja nauczone wagi modelu dla różnych wartości parametru C (należy użyc plt.imshow). Z czego wynikają różnice w narysowanych obrazkach? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in [0.01, 0.1, 1, 10, 50, 100]:\n",
    "    model = LogisticRegression(C=c) \n",
    "    model.fit(X_train[0:N], Y_train[0:N])\n",
    "    Y_test_predicted = model.predict(X_test)\n",
    "    plt.imshow(model.coef_)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na powyższych wykresach widać, że im mniejsza jest wartość parametru C tym mapa jest ciemniejsza z czego można wywnioskować, że wagi są mniej rozproszone. W modelach parametr C powinien być ustalany w zależności od tego jak bardzo ufamy danym, które już otrzymaliśmy- im większa ufność tym mniejsze C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Krok 3: Tworzymy caly model zmniejszając wielkość przykładów\n",
    "\n",
    "W scikit-learn możemy połączyć pare modeli w **pipeline**, który sam implementuje interfejs **Estimator**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=20)\n",
    "pca.fit(X_train)\n",
    "X_train_transf = pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logistic = linear_model.LogisticRegression(C=0.1)\n",
    "logistic.fit(X_train_transf, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('pca', pca), ('logistic', logistic)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Zobaczmy na dokładność modelu\n",
    "Y_test_predicted = pipe.predict(X_test)\n",
    "print \"Dokładność modelu wytrenowanego to: \",100*sklearn.metrics.accuracy_score(Y_test, Y_test_predicted), \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "Jak widać, na rozważanych zbiorach, można osiągnąć wysoką dokładność (>85%) używając prostych modeli. Niestety na bardziej skomplikowanych danych (np. CIFAR-100, https://www.cs.toronto.edu/~kriz/cifar.html) nie jest już tak prosto.\n",
    "\n",
    "Tradycyjne architektury, które były popularne do niedawna, używały ręcznej ekstrakcji \"lepszych\" cech:\n",
    "\n",
    "<img src=\"figures/L1/standard.jpg\">\n",
    "\n",
    "Deep Learning jest poddziedziną machine learningu, gdzie rozważamy architektury, które samoistnie uczą się cech na tyle dobrych, że dokładnie takie same modele jak Państwu pokazywaliśmy działają z zadowalającą precyzją\n",
    "\n",
    "<img src=\"figures/L1/features.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
