{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L11 - Uczenie reprezentacji\n",
    "\n",
    "Na dzisiejszych zajęciach dowiemy się o paru metodach nauki reprezentacji (a nie gęstości danych), co może być przydatne do projektu (w szczególności autoenkodery).\n",
    "\n",
    "Ref:\n",
    "* (Repr. Learning, review) http://www.cl.uni-heidelberg.de/courses/ws14/deepl/BengioETAL12.pdf\n",
    "* (Deep Learning book, ch. 15) http://www.deeplearningbook.org/\n",
    "* (Autoenkodery w Keras) https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "* (Bardzo polecam, czego uczą się autoenkodery) https://gabgoh.github.io/ThoughtVectors/\n",
    "* (Isomap) http://wearables.cc.gatech.edu/paper_of_week/isomap.pdf\n",
    "* (Dobry opis konwolucyjnych sieci) http://cs231n.github.io/convolutional-networks/\n",
    "* (Slajdy prof. Hintona na temat Isomap oraz tSNE) https://www.cs.toronto.edu/~hinton/csc2535/notes/lec11new.ppt\n",
    "* (How to use tsne) http://distill.pub/2016/misread-tsne/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import time as time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.datasets.samples_generator import make_swiss_roll\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.decomposition import RandomizedPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tsne\n",
      "  Using cached tsne-0.1.7.tar.gz\n",
      "Requirement already satisfied: Cython>=0.19.1 in c:\\users\\micociepka\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from tsne)\n",
      "Requirement already satisfied: numpy>=1.7.1 in c:\\users\\micociepka\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from tsne)\n",
      "Requirement already satisfied: scipy>=0.12.0 in c:\\users\\micociepka\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages (from tsne)\n",
      "Building wheels for collected packages: tsne\n",
      "  Running setup.py bdist_wheel for tsne: started\n",
      "  Running setup.py bdist_wheel for tsne: finished with status 'error'\n",
      "  Complete output from command C:\\Users\\micociepka\\AppData\\Local\\Continuum\\Anaconda2\\python.exe -u -c \"import setuptools, tokenize;__file__='c:\\\\users\\\\micoci~1\\\\appdata\\\\local\\\\temp\\\\pip-build-xydxax\\\\tsne\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d c:\\users\\micoci~1\\appdata\\local\\temp\\tmpbshqhdpip-wheel- --python-tag cp27:\n",
      "  Warning: Extension name 'bh_sne' does not match fully qualified name 'tsne.bh_sne' of 'tsne/bh_sne.pyx'\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-2.7\n",
      "  creating build\\lib.win-amd64-2.7\\tsne\n",
      "  copying tsne\\_version.py -> build\\lib.win-amd64-2.7\\tsne\n",
      "  copying tsne\\__init__.py -> build\\lib.win-amd64-2.7\\tsne\n",
      "  creating build\\lib.win-amd64-2.7\\tsne\\tests\n",
      "  copying tsne\\tests\\test_iris.py -> build\\lib.win-amd64-2.7\\tsne\\tests\n",
      "  copying tsne\\tests\\test_seed.py -> build\\lib.win-amd64-2.7\\tsne\\tests\n",
      "  copying tsne\\tests\\__init__.py -> build\\lib.win-amd64-2.7\\tsne\\tests\n",
      "  UPDATING build\\lib.win-amd64-2.7\\tsne/_version.py\n",
      "  set build\\lib.win-amd64-2.7\\tsne/_version.py to '0.1.7'\n",
      "  running build_ext\n",
      "  building 'bh_sne' extension\n",
      "  creating build\\temp.win-amd64-2.7\n",
      "  creating build\\temp.win-amd64-2.7\\Release\n",
      "  creating build\\temp.win-amd64-2.7\\Release\\tsne\n",
      "  creating build\\temp.win-amd64-2.7\\Release\\tsne\\bh_sne_src\n",
      "  C:\\Users\\micociepka\\AppData\\Local\\Programs\\Common\\Microsoft\\Visual C++ for Python\\9.0\\VC\\Bin\\amd64\\cl.exe /c /nologo /Ox /MD /W3 /GS- /DNDEBUG -IC:\\Users\\micociepka\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\numpy\\core\\include -I/usr/local/include -Itsne/bh_sne_src/ -IC:\\Users\\micociepka\\AppData\\Local\\Continuum\\Anaconda2\\include -IC:\\Users\\micociepka\\AppData\\Local\\Continuum\\Anaconda2\\PC /Tptsne/bh_sne.cpp /Fobuild\\temp.win-amd64-2.7\\Release\\tsne/bh_sne.obj -msse2 -O3 -fPIC -w\n",
      "  cl : Command line warning D9025 : overriding '/W3' with '/w'\n",
      "  cl : Command line warning D9002 : ignoring unknown option '-msse2'\n",
      "  cl : Command line warning D9002 : ignoring unknown option '-O3'\n",
      "  cl : Command line warning D9002 : ignoring unknown option '-fPIC'\n",
      "  bh_sne.cpp\n",
      "  c:\\users\\micociepka\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages\\numpy\\core\\include\\numpy\\npy_1_7_deprecated_api.h(12) : Warning Msg: Using deprecated NumPy API, disable it by #defining NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\n",
      "  C:\\Users\\micociepka\\AppData\\Local\\Programs\\Common\\Microsoft\\Visual C++ for Python\\9.0\\VC\\Include\\xlocale(342) : warning C4530: C++ exception handler used, but unwind semantics are not enabled. Specify /EHsc\n",
      "  C:\\Users\\micociepka\\AppData\\Local\\Programs\\Common\\Microsoft\\Visual C++ for Python\\9.0\\VC\\Bin\\amd64\\cl.exe /c /nologo /Ox /MD /W3 /GS- /DNDEBUG -IC:\\Users\\micociepka\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\numpy\\core\\include -I/usr/local/include -Itsne/bh_sne_src/ -IC:\\Users\\micociepka\\AppData\\Local\\Continuum\\Anaconda2\\include -IC:\\Users\\micociepka\\AppData\\Local\\Continuum\\Anaconda2\\PC /Tptsne/bh_sne_src/quadtree.cpp /Fobuild\\temp.win-amd64-2.7\\Release\\tsne/bh_sne_src/quadtree.obj -msse2 -O3 -fPIC -w\n",
      "  cl : Command line warning D9025 : overriding '/W3' with '/w'\n",
      "  cl : Command line warning D9002 : ignoring unknown option '-msse2'\n",
      "  cl : Command line warning D9002 : ignoring unknown option '-O3'\n",
      "  cl : Command line warning D9002 : ignoring unknown option '-fPIC'\n",
      "  quadtree.cpp\n",
      "  tsne/bh_sne_src/quadtree.cpp(12) : fatal error C1083: Cannot open include file: 'cblas.h': No such file or directory\n",
      "  error: command 'C:\\\\Users\\\\micociepka\\\\AppData\\\\Local\\\\Programs\\\\Common\\\\Microsoft\\\\Visual C++ for Python\\\\9.0\\\\VC\\\\Bin\\\\amd64\\\\cl.exe' failed with exit status 2\n",
      "  \n",
      "  ----------------------------------------\n",
      "  Running setup.py clean for tsne\n",
      "Failed to build tsne\n",
      "Installing collected packages: tsne\n",
      "  Running setup.py install for tsne: started\n",
      "    Running setup.py install for tsne: finished with status 'error'\n",
      "    Complete output from command C:\\Users\\micociepka\\AppData\\Local\\Continuum\\Anaconda2\\python.exe -u -c \"import setuptools, tokenize;__file__='c:\\\\users\\\\micoci~1\\\\appdata\\\\local\\\\temp\\\\pip-build-xydxax\\\\tsne\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record c:\\users\\micoci~1\\appdata\\local\\temp\\pip-op7fpl-record\\install-record.txt --single-version-externally-managed --compile:\n",
      "    Warning: Extension name 'bh_sne' does not match fully qualified name 'tsne.bh_sne' of 'tsne/bh_sne.pyx'\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-2.7\n",
      "    creating build\\lib.win-amd64-2.7\\tsne\n",
      "    copying tsne\\_version.py -> build\\lib.win-amd64-2.7\\tsne\n",
      "    copying tsne\\__init__.py -> build\\lib.win-amd64-2.7\\tsne\n",
      "    creating build\\lib.win-amd64-2.7\\tsne\\tests\n",
      "    copying tsne\\tests\\test_iris.py -> build\\lib.win-amd64-2.7\\tsne\\tests\n",
      "    copying tsne\\tests\\test_seed.py -> build\\lib.win-amd64-2.7\\tsne\\tests\n",
      "    copying tsne\\tests\\__init__.py -> build\\lib.win-amd64-2.7\\tsne\\tests\n",
      "    UPDATING build\\lib.win-amd64-2.7\\tsne/_version.py\n",
      "    set build\\lib.win-amd64-2.7\\tsne/_version.py to '0.1.7'\n",
      "    running build_ext\n",
      "    building 'bh_sne' extension\n",
      "    creating build\\temp.win-amd64-2.7\n",
      "    creating build\\temp.win-amd64-2.7\\Release\n",
      "    creating build\\temp.win-amd64-2.7\\Release\\tsne\n",
      "    creating build\\temp.win-amd64-2.7\\Release\\tsne\\bh_sne_src\n",
      "    C:\\Users\\micociepka\\AppData\\Local\\Programs\\Common\\Microsoft\\Visual C++ for Python\\9.0\\VC\\Bin\\amd64\\cl.exe /c /nologo /Ox /MD /W3 /GS- /DNDEBUG -IC:\\Users\\micociepka\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\numpy\\core\\include -I/usr/local/include -Itsne/bh_sne_src/ -IC:\\Users\\micociepka\\AppData\\Local\\Continuum\\Anaconda2\\include -IC:\\Users\\micociepka\\AppData\\Local\\Continuum\\Anaconda2\\PC /Tptsne/bh_sne.cpp /Fobuild\\temp.win-amd64-2.7\\Release\\tsne/bh_sne.obj -msse2 -O3 -fPIC -w\n",
      "    cl : Command line warning D9025 : overriding '/W3' with '/w'\n",
      "    cl : Command line warning D9002 : ignoring unknown option '-msse2'\n",
      "    cl : Command line warning D9002 : ignoring unknown option '-O3'\n",
      "    cl : Command line warning D9002 : ignoring unknown option '-fPIC'\n",
      "    bh_sne.cpp\n",
      "    c:\\users\\micociepka\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages\\numpy\\core\\include\\numpy\\npy_1_7_deprecated_api.h(12) : Warning Msg: Using deprecated NumPy API, disable it by #defining NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\n",
      "    C:\\Users\\micociepka\\AppData\\Local\\Programs\\Common\\Microsoft\\Visual C++ for Python\\9.0\\VC\\Include\\xlocale(342) : warning C4530: C++ exception handler used, but unwind semantics are not enabled. Specify /EHsc\n",
      "    C:\\Users\\micociepka\\AppData\\Local\\Programs\\Common\\Microsoft\\Visual C++ for Python\\9.0\\VC\\Bin\\amd64\\cl.exe /c /nologo /Ox /MD /W3 /GS- /DNDEBUG -IC:\\Users\\micociepka\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\numpy\\core\\include -I/usr/local/include -Itsne/bh_sne_src/ -IC:\\Users\\micociepka\\AppData\\Local\\Continuum\\Anaconda2\\include -IC:\\Users\\micociepka\\AppData\\Local\\Continuum\\Anaconda2\\PC /Tptsne/bh_sne_src/quadtree.cpp /Fobuild\\temp.win-amd64-2.7\\Release\\tsne/bh_sne_src/quadtree.obj -msse2 -O3 -fPIC -w\n",
      "    cl : Command line warning D9025 : overriding '/W3' with '/w'\n",
      "    cl : Command line warning D9002 : ignoring unknown option '-msse2'\n",
      "    cl : Command line warning D9002 : ignoring unknown option '-O3'\n",
      "    cl : Command line warning D9002 : ignoring unknown option '-fPIC'\n",
      "    quadtree.cpp\n",
      "    tsne/bh_sne_src/quadtree.cpp(12) : fatal error C1083: Cannot open include file: 'cblas.h': No such file or directory\n",
      "    error: command 'C:\\\\Users\\\\micociepka\\\\AppData\\\\Local\\\\Programs\\\\Common\\\\Microsoft\\\\Visual C++ for Python\\\\9.0\\\\VC\\\\Bin\\\\amd64\\\\cl.exe' failed with exit status 2\n",
      "    \n",
      "    ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Failed building wheel for tsne\n",
      "Command \"C:\\Users\\micociepka\\AppData\\Local\\Continuum\\Anaconda2\\python.exe -u -c \"import setuptools, tokenize;__file__='c:\\\\users\\\\micoci~1\\\\appdata\\\\local\\\\temp\\\\pip-build-xydxax\\\\tsne\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record c:\\users\\micoci~1\\appdata\\local\\temp\\pip-op7fpl-record\\install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in c:\\users\\micoci~1\\appdata\\local\\temp\\pip-build-xydxax\\tsne\\\n"
     ]
    }
   ],
   "source": [
    "!pip install tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named tsne",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cf89bf0c6c84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mtsne\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbh_sne\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named tsne"
     ]
    }
   ],
   "source": [
    "from tsne import bh_sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zbiory danych\n",
    "\n",
    "* Swissroll (2 -> 3)\n",
    "\n",
    "* MNIST (? -> 784), ? pewnie nie dużo większe niż 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Swissroll\n",
    "n_samples = 1500\n",
    "noise = 0.05\n",
    "X_swissroll, z_swissroll = make_swiss_roll(n_samples, noise)\n",
    "X_swissroll[:, 1] *= .5\n",
    "X_test_swissroll, z_test_swissroll = make_swiss_roll(n_samples/10, noise)\n",
    "X_test_swissroll[:, 1] *= .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Swissroll noiseless\n",
    "n_samples = 10000\n",
    "noise = 0.00\n",
    "X_swissroll_noiseless, z_swissroll = make_swiss_roll(n_samples, noise)\n",
    "X_swissroll_noiseless[:, 1] *= 0.5\n",
    "X_test_swissroll_noiseless, z_test_swissroll = make_swiss_roll(n_samples/10, noise)\n",
    "X_test_swissroll_noiseless[:, 1] *= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## MNIST\n",
    "(x_mnist_train, y_mnist_train), (x_mnist_test, y_mnist_test) = mnist.load_data()\n",
    "x_mnist_train = x_mnist_train.astype('float32') / 255.\n",
    "x_mnist_test = x_mnist_test.astype('float32') / 255.\n",
    "x_mnist_train = x_mnist_train.reshape((len(x_mnist_train), np.prod(x_mnist_train.shape[1:])))\n",
    "x_mnist_test = x_mnist_test.reshape((len(x_mnist_test), np.prod(x_mnist_test.shape[1:])))\n",
    "\n",
    "ids_train_small = np.random.choice(len(x_mnist_train), 1500, replace=False)\n",
    "ids_test_small = np.random.choice(len(x_mnist_test), 1500, replace=False)\n",
    "x_mnist_train_small = x_mnist_train[ids_train_small]\n",
    "x_mnist_test_small = x_mnist_test[ids_test_small]\n",
    "y_mnist_train_small = y_mnist_train[ids_train_small]\n",
    "y_mnist_test_small = y_mnist_test[ids_test_small]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_autoencoder(activation='relu', output_activation='sigmoid', hidden_dims=[32], input_dim=784, sigma=0.0, l1_activity=[0.0,0.0]):\n",
    "    # this is our input placeholder\n",
    "    input_img = Input(shape=(input_dim,))\n",
    "    \n",
    "    if sigma > 0:\n",
    "        input_enc = GaussianNoise(sigma)(input_img)\n",
    "    else:\n",
    "        input_enc = input_img\n",
    "    \n",
    "    # \"encoded\" is the encoded representation of the input\n",
    "    x = input_enc\n",
    "    for hidden_dim,l1 in zip(hidden_dims, l1_activity):\n",
    "        x = Dense(hidden_dim, activation=activation, activity_regularizer=regularizers.l1(l1))(x)\n",
    "    encoded = x\n",
    "    for hidden_dim in reversed(hidden_dims[1:]):\n",
    "        x = Dense(hidden_dim, activation=activation)(x)\n",
    "        \n",
    "    # \"decoded\" is the lossy reconstruction of the input\n",
    "    decoded = Dense(input_dim, activation=output_activation)(x)\n",
    "    \n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    encoder = Model(input_img, encoded)\n",
    "\n",
    "    # create a placeholder for an encoded \n",
    "    encoded_input = Input(shape=(hidden_dims[-1],))\n",
    "    # retrieve the last layer of the autoencoder model\n",
    "    decoder_layer = autoencoder.layers[-1]\n",
    "    # create the decoder model\n",
    "    decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "    \n",
    "    return autoencoder, encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_conv_mnist_autoencoder():\n",
    "    # Rozmiary konwolucji sa dobrane specjalnie tak aby decoded mial rozmiar x\n",
    "    \n",
    "    input_img = Input(shape=(28, 28, 1)) \n",
    "\n",
    "    # this is our input placeholder\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same', data_format=\"channels_last\")(encoded)\n",
    "    x = UpSampling2D((2, 2), data_format=\"channels_last\")(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same', data_format=\"channels_last\")(x)\n",
    "    x = UpSampling2D((2, 2), data_format=\"channels_last\")(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', data_format=\"channels_last\")(x)\n",
    "    x = UpSampling2D((2, 2), data_format=\"channels_last\")(x)\n",
    "    \n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same', data_format=\"channels_last\")(x)\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    encoder = Model(input_img, encoded)\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postawienie problemu\n",
    "\n",
    "## Odwracanie funkcji\n",
    "\n",
    "Z jednej strony możemy patrzeć na problem uczenia nienadzorowanego jako problemu \"odwrócenia\" funkcji generującej dane.\n",
    "\n",
    "Przykładowo, punkt ze zbioru danych swissroll powstaje przez wylosowanie 2 zmiennych $u_1$ oraz $u_2$ a potem ich zanurzeniu w 3 wymiarach. Ten proces staramy się odwrócić i znaleźć (nieliniowy) układ współrzędnych w którym swissroll \"jest wypłaszczony\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = p3.Axes3D(fig)\n",
    "ax.view_init(7, -80)\n",
    "ax.plot3D(X_swissroll[:,0], X_swissroll[:, 1], X_swissroll[:, 2], 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=300 src=\"https://github.com/gmum/ml2017/raw/master/figures/L11/swissroll.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum likelihood\n",
    "\n",
    "Z drugiej strony popularnym podejściem jest stawianie problemu uczenia nienadzorowanego jako znajdowania rozwiązania \n",
    "\n",
    "$$ \\theta^{*} = argmax_{\\theta} \\mathbb{E}[p_\\theta(x)] $$\n",
    "\n",
    "Co istotne, jeśli naszym celem jest nauka cech (a nie aproksymacja gęstości), to nie ma zadnych gwarancji że podejścia typu \"maximum likelihood\" nauczą się ciekawych cech, patrz np. http://www.inference.vc/maximum-likelihood-for-representation-learning-2/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA / liniowy autoenkoder\n",
    "\n",
    "Najprostsza sieć neuronowa do nauki cech jednocześnie implementuje PCA (\"In the auto-associative case ... and therefore the unique locally and globally optimal map W is the orthogonal projection onto the space spanned by the first pp eigenvectors of ΣXX\").\n",
    "\n",
    "<img src=\"https://github.com/gmum/ml2017/raw/master/figures/L11/autoencoder_schema.jpg\" width=500>\n",
    "\n",
    "Dla liniowej funkcji enkoder metoda znajduje to samo co PCA:\n",
    "\n",
    "<img src=\"https://github.com/gmum/ml2017/raw/master/figures/L11/pca.png\" width=500>\n",
    "\n",
    "Podstawowa idea: **utrata informacji**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swissroll\n",
    "\n",
    "Wniosek: bardzo ciężko nauczyć się tak dobrej reprezentacji jak isomap 1 warstwowym enkoderem, ponieważ jest on i tak mocno liniowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "autoencoder, encoder, decoder = build_autoencoder(activation='linear', output_activation='linear',\n",
    "                                                 hidden_dims=[2], input_dim=3)\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "\n",
    "autoencoder.fit(X_swissroll, X_swissroll,\n",
    "                epochs=50,\n",
    "                batch_size=100,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test_swissroll, X_test_swissroll))\n",
    "\n",
    "# Jak widac, swissroll nie ma globalnej struktury liniowej, stad porazka metody\n",
    "X_test_swissroll_proj = encoder.predict(X_test_swissroll)\n",
    "\n",
    "plt.scatter(X_test_swissroll_proj[:, 0], X_test_swissroll_proj[:, 1], c=z_test_swissroll, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Najpierw narysujmy przestrzeń 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = RandomizedPCA(n_components=2, iterated_power=15, whiten=True)\n",
    "fig, plot = plt.subplots()\n",
    "fig.set_size_inches(8, 8)\n",
    "plt.prism()\n",
    "x_mnist_train_transformed_small = pca.fit_transform(x_mnist_train_small.reshape(x_mnist_train_small.shape[0], -1))\n",
    "plot.scatter(x_mnist_train_transformed_small[:, 0], x_mnist_train_transformed_small[:, 1], c=y_mnist_train_small)\n",
    "plot.set_xticks(())\n",
    "plot.set_yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Teraz rozważmy hidden dim > 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "autoencoder, encoder, decoder = build_autoencoder(activation='linear', output_activation='sigmoid',\n",
    "                                                 hidden_dim=32, input_dim=784)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(x_mnist_train, x_mnist_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_mnist_test, x_mnist_test))\n",
    "\n",
    "encoded_imgs = encoder.predict(x_mnist_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_mnist_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samplowanie\n",
    "\n",
    "Poza uczeniem się cech, wiele modeli pozwala na efektywne \"wymyślanie\" (generowanie) przykładów. W niektórych modelach jest to trudne, w innych proste. W przypadku typowych autoenkoderów możliwa jest interpolacja między przykładami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Policzmy interpolacje miedzy 7 a 2 ze zbioru testowego\n",
    "interpolated = []\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i, lerp in enumerate(np.linspace(0, 1, n)):\n",
    "    interpolated.append(decoder.predict(lerp*encoded_imgs[0:1] + (1-lerp)*encoded_imgs[1:2]))\n",
    "    \n",
    "    ax = plt.subplot(1, n, i + 1)\n",
    "    plt.imshow(interpolated[-1].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problemy PCA / liniowego autoenkodera\n",
    "\n",
    "* Brak modelu prawdopodobieństwa (0 poza nieskończonie małym podzbiorem) - Probabilistic PCA (PPCA), patrz np. http://edwardlib.org/tutorials/probabilistic-pca oraz variational/denoising autoenckoder\n",
    "* Ciężko generować z modeli (rozwiązywane przez VAE/PPCA)\n",
    "* Zakłada globalną strukture euklidesową - MDS generalizuje na dowolną metryke\n",
    "* Zakłada globalną strukturę liniową - Isomap/LLE/kernelPCA/nieliniowe autoenkodery wszystkie rozwiązać ten problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isomap\n",
    "\n",
    "Isomap jest w pewnym sensie rozszerzeniem PCA do izometrycznych odzworowań (solver w scikit-learn używa kernel PCA wewnątrz). Dalsze modyfikacje rozszerzają do odwzorowań konforemnych (zachowujących kąty). Przez \"rozszerzenie\" rozumiemy tutaj, że Isomap rozwiązuje problem szukania odwzorowania odwrotnego przy odpowiednio dużej ilości punktów (podczas gdy PCA nigdy nie rozwiąże swissroll, nawet przy nieskończonej próbce danych).\n",
    "\n",
    "* Isomap w tradycyjnym sformułowaniu nie pozwala na predykcję na nowych punkach (czyli np. samplowanie).\n",
    "\n",
    "* Isomap ma złożoność O(n^3) przez co niestety jest bardziej ciekawostką, za to całkiem podobne algorytmy, np. t-SNE są dużo szybsze.\n",
    "\n",
    "<img src=\"https://github.com/gmum/ml2017/raw/master/figures/L11/isomap_distance.png\" width=800>\n",
    "\n",
    "\"PCA\n",
    "finds a low-dimensional embedding of the\n",
    "data points that best preserves their variance\n",
    "as measured in the high-dimensional input\n",
    "space. Classical MDS finds an embedding\n",
    "that preserves the interpoint distances, equivalent\n",
    "to PCA when those distances are Euclidean.\n",
    "However, many data sets contain\n",
    "essential nonlinear structures that are invisible\n",
    "to PCA and MDS (4, 5, 11, 14). For\n",
    "example, both methods fail to detect the true\n",
    "degrees of freedom of the face data set (Fig.\n",
    "1A), or even its intrinsic three-dimensionality\n",
    "(Fig. 2A).\"\n",
    "\n",
    "\"Just as PCA and MDS are guaranteed,\n",
    "given sufficient data, to recover the true\n",
    "structure of linear manifolds, Isomap is guaranteed\n",
    "asymptotically to recover the true dimensionality\n",
    "and geometric structure of a\n",
    "strictly larger class of nonlinear manifolds\"\n",
    "\n",
    "(Cytaty z http://wearables.cc.gatech.edu/paper_of_week/isomap.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swissroll\n",
    "\n",
    "Isomap, odwrotnie od PCA/liniowego autoenkodera rozwiązuje całkiem nieźle swissroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isomap = Isomap().fit(X_swissroll)\n",
    "X_test_swissroll_proj = isomap.transform(X_test_swissroll)\n",
    "# Jak widac, swissroll nie ma globalnej struktury liniowej, stad porazka metody\n",
    "plt.scatter(X_test_swissroll_proj[:, 0], X_test_swissroll_proj[:, 1], c=z_test_swissroll, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Isomap na MNIST wizualnie wydaje sie podobny, ale dalsze eksperymenty (samplowanie) pokazuje że jest zwykle lepszy\n",
    "\n",
    "isomap = Isomap()\n",
    "fig, plot = plt.subplots()\n",
    "fig.set_size_inches(8, 8)\n",
    "plt.prism()\n",
    "x_mnist_train_transformed_small = isomap.fit_transform(x_mnist_train_small.reshape(x_mnist_train_small.shape[0], -1))\n",
    "plot.scatter(x_mnist_train_transformed_small[:, 0], x_mnist_train_transformed_small[:, 1], c=y_mnist_train_small)\n",
    "plot.set_xticks(())\n",
    "plot.set_yticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samplowanie\n",
    "\n",
    "Orginalny isomap nie pozwala, ale są rozszerzenia. Jak widać (z pracy http://web.mit.edu/cocosci/Papers/sci_reprint.pdf) samplowanie  jest bardziej naturalne (porównaj z wykresem z sekcji o PCA):\n",
    "\n",
    "<img src=\"https://github.com/gmum/ml2017/raw/master/figures/L11/sampling_isomap.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE\n",
    "\n",
    "t-SNE służy do wizualizacji, nie nauki cech! Jest zamieszczony ze względu na ogromną popularność.\n",
    "\n",
    "Ref: http://distill.pub/2016/misread-tsne/\n",
    "\n",
    "Różnice z isomap: \n",
    "* crowding problem (high dim -> 2 powoduje nowe problemy)\n",
    "* O(n^2), a nawet O(nlgn) (w porównaniu do złożonosci sześciennej podstawowej wersji Isomap)\n",
    "\n",
    "Parametry (ważne):\n",
    "* Learning rate\n",
    "* Perplexity\n",
    "\n",
    "\"A second feature of t-SNE is a tuneable parameter, “perplexity,” which says (loosely) how to balance attention between local and global aspects of your data. The parameter is, in a sense, a guess about the number of close neighbors each point has. The perplexity value has a complex effect on the resulting pictures. The original paper says, “The performance of SNE is fairly robust to changes in the perplexity, and typical values are between 5 and 50.” But the story is more nuanced than that. Getting the most from t-SNE may mean analyzing multiple plots with different perplexities.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swissroll\n",
    "\n",
    "Dla roznych perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perplexities = [2, 5, 10, 20, 50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Policzmy interpolacje miedzy 7 a 2 ze zbioru testowego\n",
    "# Prosze zwrocic na oderwanie ostatniego kawalka na ostatnim z prawej obrazku\n",
    "\n",
    "interpolated = []\n",
    "n = len(perplexities)\n",
    "plt.figure(figsize=(len(perplexities) * 5, 5))\n",
    "for i, p in enumerate(perplexities):\n",
    "    print((i, p))\n",
    "    ax = plt.subplot(1, n, i + 1)\n",
    "    X_swissroll_proj = bh_sne(X_swissroll.astype(\"float64\"), perplexity=p)\n",
    "    plt.scatter(X_swissroll_proj[:, 0], X_swissroll_proj[:, 1], c=z_swissroll, cmap=plt.cm.Spectral)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie [1 pkt]\n",
    "\n",
    "Czemu ostatni obrazek z prawej (dla maksymalnego perplexity) ma oderwany kawalek?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "\n",
    "t-SNE ma też problemy z \"surowymi\" danymi (nie jest to metoda nauki reprezentacji). Jak zobaczymy w ćwiczeniu, t-SNE za to działa świetnie do wizualizacji już nauczonych cech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dla t-sne srednia nie jest istotna, ale skala tak\n",
    "x_mnist_train_small_standardized = x_mnist_train_small/ (1e-10 + np.std(x_mnist_train_small, axis=0, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Policzmy interpolacje miedzy 7 a 2 ze zbioru testowego\n",
    "interpolated = []\n",
    "n = len(perplexities)\n",
    "plt.figure(figsize=(len(perplexities) * 5, 5))\n",
    "for i, p in enumerate(perplexities):\n",
    "    print((i, p))\n",
    "    ax = plt.subplot(1, n, i + 1)\n",
    "    x_mnist_train_small_standardized_proj = bh_sne(x_mnist_train_small_standardized.astype(\"float64\"), perplexity=p)\n",
    "    plt.scatter(x_mnist_train_small_standardized_proj[:, 0], x_mnist_train_small_standardized_proj[:, 1], \n",
    "                c=y_mnist_train_small, cmap=plt.cm.Spectral)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nieliniowy autoenkoder\n",
    "\n",
    "Ref: http://gabgoh.github.io/ThoughtVectors/, https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "\n",
    "Podstawowa idea: utrata informacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swissroll\n",
    "\n",
    "Wniosek: mimo dobrej dokładnośc (MSE) ciężko znaleźć poprawne cechy dla zbioru danych swissroll. \n",
    "\n",
    "1. Koszt autoenkodera nie jest tym samym co znajdowanie dobrych cech (3 cechy też dobrze kodują).\n",
    "\n",
    "2. Transformacja ktora znajduje rozplątanie jest bardzo nieliniowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std = StandardScaler().fit(X_swissroll_noiseless)\n",
    "X_test_swissroll_noiseless_std = std.transform(X_test_swissroll_noiseless)\n",
    "X_swissroll_noiseless_std = std.transform(X_swissroll_noiseless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Blad MSE 0.3 jest calkiem dobry\n",
    "\n",
    "autoencoder, encoder, decoder = build_autoencoder(activation='relu', output_activation='linear',\n",
    "                                                 hidden_dims=[15, 2], input_dim=3, sigma=0.005)\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "\n",
    "autoencoder.fit(X_swissroll_noiseless_std, X_swissroll_noiseless_std,\n",
    "                epochs=150,\n",
    "                batch_size=100,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test_swissroll_noiseless_std, X_test_swissroll_noiseless_std))\n",
    "\n",
    "# Jak widac, swissroll nie ma globalnej struktury liniowej, stad porazka metody\n",
    "X_test_swissroll_noiseless_std_proj = encoder.predict(X_test_swissroll_noiseless_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_test_swissroll_noiseless_std_proj[:, 0], X_test_swissroll_noiseless_std_proj[:, 1], c=z_test_swissroll, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interrim - konwolucje\n",
    "\n",
    "Ref: http://cs231n.github.io/convolutional-networks/\n",
    "\n",
    "<img src=\"figures/L11/conv1.jpeg\" width=500>\n",
    "\n",
    "(Wersja animowana dostępna na http://cs231n.github.io/convolutional-networks/)\n",
    "\n",
    "<img src=\"figures/L11/conv3.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "\n",
    "(Rozważamy tutaj konwolucje, patrz wykład)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "autoencoder, encoder = build_conv_mnist_autoencoder()\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ~ Pare minut na typowym laptopie z CPU. Polecam uzyc GPU jak ktos ma.\n",
    "autoencoder.fit(x_mnist_train.reshape(-1, 28, 28, 1), x_mnist_train.reshape(-1, 28, 28, 1),\n",
    "                epochs=15, # Mozna juz sprawdzic wyniki po 10\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_mnist_test.reshape(-1, 28, 28, 1), x_mnist_test.reshape(-1, 28, 28, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_mnist_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(autoencoder.predict(x_mnist_test[i].reshape(1, 28, 28, 1)).reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(x_mnist_test_small.reshape(-1, 28, 28, 1)).reshape(len(x_mnist_test_small), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Policzmy interpolacje miedzy 7 a 2 ze zbioru testowego\n",
    "interpolated = []\n",
    "n = len(perplexities)\n",
    "plt.figure(figsize=(len(perplexities) * 5, 5))\n",
    "for i, p in enumerate(perplexities):\n",
    "    print((i, p))\n",
    "    ax = plt.subplot(1, n, i + 1)\n",
    "    encoded_imgs_proj = bh_sne(encoded_imgs.astype(\"float64\"), perplexity=p)\n",
    "    plt.scatter(encoded_imgs_proj[:, 0], encoded_imgs_proj[:, 1], \n",
    "                c=y_mnist_test_small, cmap=plt.cm.Spectral)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 1 - nieliniowy autoenkoder na CIFAR10 [6 pkt]\n",
    "\n",
    "1. Powtórz powyższe eksperymenty dla małej próbki CIFAR10 (patrz projekt.ipynb) [2 pkt]\n",
    "2. Sprawdź jak wygląda interpolacja dla małej próbki CIFAR10 pomiędzy 0 i 1 przykładem z zbioru testowego [2 pkt]\n",
    "3. Narysuj wykres val_loss i loss modelu z 1. [1 pkt]\n",
    "4. Czy można teoretycznie policzyć likelihood danych d;a rozważanego nieliniowego autoenkodera? Jeśli tak, to ile wynosi? [1pkt]\n",
    "\n",
    "Uwagi: \n",
    "\n",
    "* 1 wymaga przepisania autoenkodera tak aby działał na obrazkach o wymiarze z CIFAR10\n",
    "\n",
    "* 2 wymaga napisania dekodera (w tym momencie build_conv_mnist_autoencoder zwraca tylko encoder). Możesz użyć w tym celu klasy Sequential z kerasa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O czym nie wspominamy\n",
    "\n",
    "* Klastrowanie (w szczególności spectral clustering)\n",
    "* GAN \n",
    "* kernel PCA / probabilistic PCA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
